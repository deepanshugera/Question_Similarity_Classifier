{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import csv, json\n",
    "from zipfile import ZipFile\n",
    "from os.path import expanduser, exists\n",
    "import pandas as pd\n",
    "import datetime, time, json\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, TimeDistributed, Dense, Lambda, concatenate, Dropout, BatchNormalization, Convolution1D, Merge, Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import Callback, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.data_utils import get_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION_PAIRS_FILE = 'data/train.csv'\n",
    "GLOVE_FILE = 'data/glove.840B.300d.txt'\n",
    "Q1_TRAINING_DATA_FILE = 'data/q1_train.npy'\n",
    "Q2_TRAINING_DATA_FILE = 'data/q2_train.npy'\n",
    "LABEL_TRAINING_DATA_FILE = 'data/label_train.npy'\n",
    "WORD_EMBEDDING_MATRIX_FILE = 'data/word_embedding_matrix.npy'\n",
    "NB_WORDS_DATA_FILE = 'data/nb_words.json'\n",
    "MAX_NB_WORDS = 200000\n",
    "MAX_SEQUENCE_LENGTH = 25\n",
    "EMBEDDING_DIM = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP_WORDS = ['ourselves', 'hers', 'between', 'yourself', 'but', 'again', 'there', 'about', 'once', 'during', 'out', 'very', 'having', 'with', 'they', 'own', 'an', 'be', 'some', 'for', 'do', 'its', 'yours', 'such', 'into', 'of', 'most', 'itself', 'other', 'off', 'is', 's', 'am', 'or', 'who', 'as', 'from', 'him', 'each', 'the', 'themselves', 'until', 'below', 'are', 'we', 'these', 'your', 'his', 'through', 'don', 'nor', 'me', 'were', 'her', 'more', 'himself', 'this', 'down', 'should', 'our', 'their', 'while', 'above', 'both', 'up', 'to', 'ours', 'had', 'she', 'all', 'no', 'when', 'at', 'any', 'before', 'them', 'same', 'and', 'been', 'have', 'in', 'will', 'on', 'does', 'yourselves', 'then', 'that', 'because', 'what', 'over', 'why', 'so', 'can', 'did', 'not', 'now', 'under', 'he', 'you', 'herself', 'has', 'just', 'where', 'too', 'only', 'myself', 'which', 'those', 'i', 'after', 'few', 'whom', 't', 'being', 'if', 'theirs', 'my', 'against', 'a', 'by', 'doing', 'it', 'how', 'further', 'was', 'here', 'than']\n",
    "SAFE_DIV = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x):\n",
    "    x = str(x).lower()\n",
    "    x = x.replace(\",000,000\", \"m\").replace(\",000\", \"k\").replace(\"′\", \"'\").replace(\"’\", \"'\")\\\n",
    "                           .replace(\"won't\", \"will not\").replace(\"cannot\", \"can not\").replace(\"can't\", \"can not\")\\\n",
    "                           .replace(\"n't\", \" not\").replace(\"what's\", \"what is\").replace(\"it's\", \"it is\")\\\n",
    "                           .replace(\"'ve\", \" have\").replace(\"i'm\", \"i am\").replace(\"'re\", \" are\")\\\n",
    "                           .replace(\"he's\", \"he is\").replace(\"she's\", \"she is\").replace(\"'s\", \" own\")\\\n",
    "                           .replace(\"%\", \" percent \").replace(\"₹\", \" rupee \").replace(\"$\", \" dollar \")\\\n",
    "                           .replace(\"€\", \" euro \").replace(\"'ll\", \" will\")\n",
    "    x = re.sub(r\"([0-9]+)000000\", r\"\\1m\", x)\n",
    "    x = re.sub(r\"([0-9]+)000\", r\"\\1k\", x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question pairs: 404290\n"
     ]
    }
   ],
   "source": [
    "question1 = []\n",
    "question2 = []\n",
    "is_duplicate = []\n",
    "with open(QUESTION_PAIRS_FILE, encoding='utf-8') as csvfile:\n",
    "    reader = csv.DictReader(csvfile, delimiter=',')\n",
    "    for row in reader:\n",
    "        question1.append(preprocess(row['question1']))\n",
    "        question2.append(preprocess(row['question2']))\n",
    "        is_duplicate.append(row['is_duplicate'])\n",
    "print('Question pairs: %d' % len(question1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words in index: 91458\n"
     ]
    }
   ],
   "source": [
    "questions = question1 + question2\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(questions)\n",
    "question1_word_sequences = tokenizer.texts_to_sequences(question1)\n",
    "question2_word_sequences = tokenizer.texts_to_sequences(question2)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "print(\"Words in index: %d\" % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word embeddings: 2196016\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "with open(GLOVE_FILE, encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split(' ')\n",
    "        word = values[0]\n",
    "        embedding = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = embedding\n",
    "\n",
    "print('Word embeddings: %d' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null word embeddings: 24937\n"
     ]
    }
   ],
   "source": [
    "nb_words = min(MAX_NB_WORDS, len(word_index))\n",
    "word_embedding_matrix = np.zeros((nb_words + 1, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    if i > MAX_NB_WORDS:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        word_embedding_matrix[i] = embedding_vector\n",
    "\n",
    "print('Null word embeddings: %d' % np.sum(np.sum(word_embedding_matrix, axis=1) == 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of question1 data tensor: (404290, 25)\n",
      "Shape of question2 data tensor: (404290, 25)\n",
      "Shape of label tensor: (404290,)\n"
     ]
    }
   ],
   "source": [
    "q1_data = pad_sequences(question1_word_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "q2_data = pad_sequences(question2_word_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "labels = np.array(is_duplicate, dtype=int)\n",
    "print('Shape of question1 data tensor:', q1_data.shape)\n",
    "print('Shape of question2 data tensor:', q2_data.shape)\n",
    "print('Shape of label tensor:', labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(open(Q1_TRAINING_DATA_FILE, 'wb'), q1_data)\n",
    "np.save(open(Q2_TRAINING_DATA_FILE, 'wb'), q2_data)\n",
    "np.save(open(LABEL_TRAINING_DATA_FILE, 'wb'), labels)\n",
    "np.save(open(WORD_EMBEDDING_MATRIX_FILE, 'wb'), word_embedding_matrix)\n",
    "with open(NB_WORDS_DATA_FILE, 'w') as f:\n",
    "    json.dump({'nb_words': nb_words}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Variables\n",
    "MODEL_WEIGHTS_FILE = 'question_pairs_weights_cnn.h5'\n",
    "MAX_SEQUENCE_LENGTH = 25\n",
    "EMBEDDING_DIM = 300\n",
    "VALIDATION_SPLIT = 0.1\n",
    "TEST_SPLIT = 0.1\n",
    "RNG_SEED = 13371447\n",
    "NB_EPOCHS = 25\n",
    "DROPOUT = 0.1\n",
    "BATCH_SIZE = 32\n",
    "nb_filter = 32 # Number of filters to use in Convolution1D\n",
    "filter_length = 3 # Length of filter for Convolution1D\n",
    "SENT_EMBEDDING_DIM = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1_train 363861\n",
      "Q2_train 363861\n",
      "Q1_test 40429\n",
      "Q2_test 40429\n"
     ]
    }
   ],
   "source": [
    "X = np.stack((q1_data, q2_data), axis=1)\n",
    "y = labels\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SPLIT, random_state=RNG_SEED)\n",
    "Q1_train = X_train[:,0]\n",
    "Q2_train = X_train[:,1]\n",
    "Q1_test = X_test[:,0]\n",
    "Q2_test = X_test[:,1]\n",
    "print(\"Q1_train\" , len(Q1_train))\n",
    "print(\"Q2_train\" , len(Q2_train))\n",
    "print(\"Q1_test\" , len(Q1_test))\n",
    "print(\"Q2_test\" , len(Q2_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`NHWC` for data_format is deprecated, use `NWC` instead\n"
     ]
    }
   ],
   "source": [
    "question1 = Input(shape=(MAX_SEQUENCE_LENGTH,))\n",
    "question2 = Input(shape=(MAX_SEQUENCE_LENGTH,))\n",
    "question3 = Input(shape=(MAX_SEQUENCE_LENGTH,))\n",
    "question4 = Input(shape=(MAX_SEQUENCE_LENGTH,))\n",
    "q1 = Embedding(nb_words + 1, \n",
    "                 EMBEDDING_DIM, \n",
    "                 weights=[word_embedding_matrix], \n",
    "                 input_length=MAX_SEQUENCE_LENGTH, \n",
    "                 trainable=False)(question1)\n",
    "q1 = TimeDistributed(Dense(EMBEDDING_DIM, activation='relu'))(q1)\n",
    "q1 = Lambda(lambda x: K.max(x, axis=1), output_shape=(EMBEDDING_DIM, ))(q1)\n",
    "\n",
    "q2 = Embedding(nb_words + 1, \n",
    "                 EMBEDDING_DIM, \n",
    "                 weights=[word_embedding_matrix], \n",
    "                 input_length=MAX_SEQUENCE_LENGTH, \n",
    "                 trainable=False)(question2)\n",
    "q2 = TimeDistributed(Dense(EMBEDDING_DIM, activation='relu'))(q2)\n",
    "q2 = Lambda(lambda x: K.max(x, axis=1), output_shape=(EMBEDDING_DIM, ))(q2)\n",
    "\n",
    "q3 = Embedding(nb_words + 1, \n",
    "                 EMBEDDING_DIM, \n",
    "                 weights=[word_embedding_matrix], \n",
    "                 input_length=MAX_SEQUENCE_LENGTH, \n",
    "                 trainable=False)(question3)\n",
    "\n",
    "q3 = Convolution1D(filters = nb_filter, \n",
    "                         kernel_size = filter_length, \n",
    "                         padding = 'same',  activation='relu')(q3)\n",
    "q3 = Flatten()(q3)\n",
    "#q3 = Lambda(lambda x: K.max(x, axis=1), output_shape=(EMBEDDING_DIM, ))(q3)\n",
    "\n",
    "q4 = Embedding(nb_words + 1, \n",
    "                 EMBEDDING_DIM, \n",
    "                 weights=[word_embedding_matrix], \n",
    "                 input_length=MAX_SEQUENCE_LENGTH, \n",
    "                 trainable=False)(question4)\n",
    "q4 = Convolution1D(filters = nb_filter, \n",
    "                         kernel_size = filter_length, \n",
    "                         padding = 'same', activation='relu')(q4)\n",
    "q4 = Flatten()(q4)\n",
    "\n",
    "merged = concatenate([q1,q2,q3,q4])\n",
    "merged = Dense(200, activation='relu')(merged)\n",
    "merged = Dropout(DROPOUT)(merged)\n",
    "merged = BatchNormalization()(merged)\n",
    "merged = Dense(200, activation='relu')(merged)\n",
    "merged = Dropout(DROPOUT)(merged)\n",
    "merged = BatchNormalization()(merged)\n",
    "merged = Dense(200, activation='relu')(merged)\n",
    "merged = Dropout(DROPOUT)(merged)\n",
    "merged = BatchNormalization()(merged)\n",
    "merged = Dense(200, activation='relu')(merged)\n",
    "merged = Dropout(DROPOUT)(merged)\n",
    "merged = BatchNormalization()(merged)\n",
    "is_duplicate = Dense(1, activation='sigmoid')(merged)\n",
    "\n",
    "model = Model(inputs=[question1,question2,question3,question4], outputs=is_duplicate)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 25)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 25)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 25)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 25)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 25, 300)      27437700    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 25, 300)      27437700    input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 25, 300)      27437700    input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 25, 300)      27437700    input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 25, 300)      90300       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, 25, 300)      90300       embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 25, 32)       28832       embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 25, 32)       28832       embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 300)          0           time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 300)          0           time_distributed_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 800)          0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 800)          0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 2200)         0           lambda_1[0][0]                   \n",
      "                                                                 lambda_2[0][0]                   \n",
      "                                                                 flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 200)          440200      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 200)          0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 200)          800         dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 200)          40200       batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 200)          0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 200)          800         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 200)          40200       batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 200)          0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 200)          800         dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 200)          40200       batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 200)          0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 200)          800         dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 1)            201         batch_normalization_4[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 110,553,265\n",
      "Trainable params: 800,865\n",
      "Non-trainable params: 109,752,400\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training at 2018-05-06 21:20:25.968830\n",
      "Train on 327474 samples, validate on 36387 samples\n",
      "Epoch 1/25\n",
      " - 187s - loss: 0.5296 - acc: 0.7319 - val_loss: 0.4815 - val_acc: 0.7659\n",
      "Epoch 2/25\n",
      " - 183s - loss: 0.4782 - acc: 0.7667 - val_loss: 0.4634 - val_acc: 0.7725\n",
      "Epoch 3/25\n",
      " - 176s - loss: 0.4471 - acc: 0.7864 - val_loss: 0.4466 - val_acc: 0.7837\n",
      "Epoch 4/25\n",
      " - 176s - loss: 0.4228 - acc: 0.8012 - val_loss: 0.4342 - val_acc: 0.7932\n",
      "Epoch 5/25\n",
      " - 176s - loss: 0.3961 - acc: 0.8177 - val_loss: 0.4367 - val_acc: 0.7880\n",
      "Epoch 6/25\n",
      " - 176s - loss: 0.3724 - acc: 0.8307 - val_loss: 0.4263 - val_acc: 0.7989\n",
      "Epoch 7/25\n",
      " - 174s - loss: 0.3543 - acc: 0.8412 - val_loss: 0.4196 - val_acc: 0.8017\n",
      "Epoch 8/25\n",
      " - 174s - loss: 0.3380 - acc: 0.8505 - val_loss: 0.4239 - val_acc: 0.7992\n",
      "Epoch 9/25\n",
      " - 174s - loss: 0.3245 - acc: 0.8576 - val_loss: 0.4203 - val_acc: 0.8024\n",
      "Epoch 10/25\n",
      " - 174s - loss: 0.3105 - acc: 0.8649 - val_loss: 0.4469 - val_acc: 0.7856\n",
      "Epoch 11/25\n",
      " - 174s - loss: 0.2986 - acc: 0.8709 - val_loss: 0.4350 - val_acc: 0.8028\n",
      "Epoch 12/25\n",
      " - 174s - loss: 0.2888 - acc: 0.8765 - val_loss: 0.4385 - val_acc: 0.8039\n",
      "Epoch 13/25\n",
      " - 174s - loss: 0.2776 - acc: 0.8817 - val_loss: 0.4312 - val_acc: 0.8007\n",
      "Epoch 14/25\n",
      " - 174s - loss: 0.2687 - acc: 0.8861 - val_loss: 0.4347 - val_acc: 0.8061\n",
      "Epoch 15/25\n",
      " - 174s - loss: 0.2608 - acc: 0.8895 - val_loss: 0.4491 - val_acc: 0.8049\n",
      "Epoch 16/25\n",
      " - 174s - loss: 0.2532 - acc: 0.8931 - val_loss: 0.4367 - val_acc: 0.8083\n",
      "Epoch 17/25\n",
      " - 174s - loss: 0.2475 - acc: 0.8955 - val_loss: 0.4552 - val_acc: 0.7997\n",
      "Epoch 18/25\n",
      " - 174s - loss: 0.2434 - acc: 0.8978 - val_loss: 0.4765 - val_acc: 0.8031\n",
      "Epoch 19/25\n",
      " - 174s - loss: 0.2381 - acc: 0.9005 - val_loss: 0.4703 - val_acc: 0.8064\n",
      "Epoch 20/25\n",
      " - 174s - loss: 0.2354 - acc: 0.9012 - val_loss: 0.4492 - val_acc: 0.8048\n",
      "Epoch 21/25\n",
      " - 174s - loss: 0.2277 - acc: 0.9056 - val_loss: 0.4686 - val_acc: 0.7977\n",
      "Epoch 22/25\n",
      " - 174s - loss: 0.2209 - acc: 0.9083 - val_loss: 0.4572 - val_acc: 0.8010\n",
      "Epoch 23/25\n",
      " - 174s - loss: 0.2158 - acc: 0.9105 - val_loss: 0.4613 - val_acc: 0.8031\n",
      "Epoch 24/25\n",
      " - 174s - loss: 0.2093 - acc: 0.9133 - val_loss: 0.4890 - val_acc: 0.8058\n",
      "Epoch 25/25\n",
      " - 174s - loss: 0.2106 - acc: 0.9133 - val_loss: 0.4637 - val_acc: 0.8081\n",
      "Training ended at 2018-05-06 22:34:06.900886\n",
      "Minutes elapsed: 73.682197\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting training at\", datetime.datetime.now())\n",
    "t0 = time.time()\n",
    "callbacks = [ModelCheckpoint(MODEL_WEIGHTS_FILE, monitor='val_acc', save_best_only=True)]\n",
    "history = model.fit([Q1_train, Q2_train,Q1_train, Q2_train],\n",
    "                    y_train,\n",
    "                    epochs=NB_EPOCHS,\n",
    "                    validation_split=VALIDATION_SPLIT,\n",
    "                    verbose=2,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    callbacks=callbacks)\n",
    "t1 = time.time()\n",
    "print(\"Training ended at\", datetime.datetime.now())\n",
    "print(\"Minutes elapsed: %f\" % ((t1 - t0) / 60.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    epoch  training  validation\n",
      "0       1  0.731890    0.765933\n",
      "1       2  0.766739    0.772501\n",
      "2       3  0.786398    0.783686\n",
      "3       4  0.801181    0.793223\n",
      "4       5  0.817720    0.787974\n",
      "5       6  0.830719    0.798939\n",
      "6       7  0.841172    0.801687\n",
      "7       8  0.850504    0.799214\n",
      "8       9  0.857576    0.802374\n",
      "9      10  0.864936    0.785583\n",
      "10     11  0.870878    0.802787\n",
      "11     12  0.876515    0.803941\n",
      "12     13  0.881716    0.800698\n",
      "13     14  0.886064    0.806085\n",
      "14     15  0.889536    0.804930\n",
      "15     16  0.893106    0.808338\n",
      "16     17  0.895467    0.799681\n",
      "17     18  0.897784    0.803116\n",
      "18     19  0.900493    0.806359\n",
      "19     20  0.901238    0.804765\n",
      "20     21  0.905629    0.797675\n",
      "21     22  0.908329    0.801000\n",
      "22     23  0.910503    0.803062\n",
      "23     24  0.913300    0.805782\n",
      "24     25  0.913282    0.808118\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "acc = pd.DataFrame({'epoch': [ i + 1 for i in history.epoch ],\n",
    "                    'training': history.history['acc'],\n",
    "                    'validation': history.history['val_acc']})\n",
    "print(acc)\n",
    "ax = acc.iloc[:,:].plot(x='epoch',  grid=True)\n",
    "ax.set_ylabel(\"accuracy\")\n",
    "ax.set_ylim([0.0,1.0]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum accuracy at epoch 16 = 0.8083\n"
     ]
    }
   ],
   "source": [
    "max_val_acc, idx = max((val, idx) for (idx, val) in enumerate(history.history['val_acc']))\n",
    "print('Maximum accuracy at epoch', '{:d}'.format(idx+1), '=', '{:.4f}'.format(max_val_acc))\n",
    "model.load_weights(MODEL_WEIGHTS_FILE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.4326, accuracy = 0.8102\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate([Q1_test, Q2_test,Q1_test, Q2_test], y_test, verbose=0)\n",
    "print('loss = {0:.4f}, accuracy = {1:.4f}'.format(loss, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
