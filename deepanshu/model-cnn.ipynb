{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import csv, json\n",
    "from zipfile import ZipFile\n",
    "from os.path import expanduser, exists\n",
    "import pandas as pd\n",
    "import datetime, time, json\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, TimeDistributed, Dense, Lambda, concatenate, Dropout, BatchNormalization, Convolution1D, Merge, Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import Callback, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.data_utils import get_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION_PAIRS_FILE = 'data/train.csv'\n",
    "GLOVE_FILE = 'data/glove.840B.300d.txt'\n",
    "Q1_TRAINING_DATA_FILE = 'data/q1_train.npy'\n",
    "Q2_TRAINING_DATA_FILE = 'data/q2_train.npy'\n",
    "LABEL_TRAINING_DATA_FILE = 'data/label_train.npy'\n",
    "WORD_EMBEDDING_MATRIX_FILE = 'data/word_embedding_matrix.npy'\n",
    "NB_WORDS_DATA_FILE = 'data/nb_words.json'\n",
    "MAX_NB_WORDS = 200000\n",
    "MAX_SEQUENCE_LENGTH = 25\n",
    "EMBEDDING_DIM = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP_WORDS = ['ourselves', 'hers', 'between', 'yourself', 'but', 'again', 'there', 'about', 'once', 'during', 'out', 'very', 'having', 'with', 'they', 'own', 'an', 'be', 'some', 'for', 'do', 'its', 'yours', 'such', 'into', 'of', 'most', 'itself', 'other', 'off', 'is', 's', 'am', 'or', 'who', 'as', 'from', 'him', 'each', 'the', 'themselves', 'until', 'below', 'are', 'we', 'these', 'your', 'his', 'through', 'don', 'nor', 'me', 'were', 'her', 'more', 'himself', 'this', 'down', 'should', 'our', 'their', 'while', 'above', 'both', 'up', 'to', 'ours', 'had', 'she', 'all', 'no', 'when', 'at', 'any', 'before', 'them', 'same', 'and', 'been', 'have', 'in', 'will', 'on', 'does', 'yourselves', 'then', 'that', 'because', 'what', 'over', 'why', 'so', 'can', 'did', 'not', 'now', 'under', 'he', 'you', 'herself', 'has', 'just', 'where', 'too', 'only', 'myself', 'which', 'those', 'i', 'after', 'few', 'whom', 't', 'being', 'if', 'theirs', 'my', 'against', 'a', 'by', 'doing', 'it', 'how', 'further', 'was', 'here', 'than']\n",
    "SAFE_DIV = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x):\n",
    "    x = str(x).lower()\n",
    "    x = x.replace(\",000,000\", \"m\").replace(\",000\", \"k\").replace(\"′\", \"'\").replace(\"’\", \"'\")\\\n",
    "                           .replace(\"won't\", \"will not\").replace(\"cannot\", \"can not\").replace(\"can't\", \"can not\")\\\n",
    "                           .replace(\"n't\", \" not\").replace(\"what's\", \"what is\").replace(\"it's\", \"it is\")\\\n",
    "                           .replace(\"'ve\", \" have\").replace(\"i'm\", \"i am\").replace(\"'re\", \" are\")\\\n",
    "                           .replace(\"he's\", \"he is\").replace(\"she's\", \"she is\").replace(\"'s\", \" own\")\\\n",
    "                           .replace(\"%\", \" percent \").replace(\"₹\", \" rupee \").replace(\"$\", \" dollar \")\\\n",
    "                           .replace(\"€\", \" euro \").replace(\"'ll\", \" will\")\n",
    "    x = re.sub(r\"([0-9]+)000000\", r\"\\1m\", x)\n",
    "    x = re.sub(r\"([0-9]+)000\", r\"\\1k\", x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question pairs: 404290\n"
     ]
    }
   ],
   "source": [
    "question1 = []\n",
    "question2 = []\n",
    "is_duplicate = []\n",
    "with open(QUESTION_PAIRS_FILE, encoding='utf-8') as csvfile:\n",
    "    reader = csv.DictReader(csvfile, delimiter=',')\n",
    "    for row in reader:\n",
    "        question1.append(preprocess(row['question1']))\n",
    "        question2.append(preprocess(row['question2']))\n",
    "        is_duplicate.append(row['is_duplicate'])\n",
    "print('Question pairs: %d' % len(question1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words in index: 91458\n"
     ]
    }
   ],
   "source": [
    "questions = question1 + question2\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(questions)\n",
    "question1_word_sequences = tokenizer.texts_to_sequences(question1)\n",
    "question2_word_sequences = tokenizer.texts_to_sequences(question2)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "print(\"Words in index: %d\" % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word embeddings: 2196016\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "with open(GLOVE_FILE, encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split(' ')\n",
    "        word = values[0]\n",
    "        embedding = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = embedding\n",
    "\n",
    "print('Word embeddings: %d' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null word embeddings: 24937\n"
     ]
    }
   ],
   "source": [
    "nb_words = min(MAX_NB_WORDS, len(word_index))\n",
    "word_embedding_matrix = np.zeros((nb_words + 1, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    if i > MAX_NB_WORDS:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        word_embedding_matrix[i] = embedding_vector\n",
    "\n",
    "print('Null word embeddings: %d' % np.sum(np.sum(word_embedding_matrix, axis=1) == 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of question1 data tensor: (404290, 25)\n",
      "Shape of question2 data tensor: (404290, 25)\n",
      "Shape of label tensor: (404290,)\n"
     ]
    }
   ],
   "source": [
    "q1_data = pad_sequences(question1_word_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "q2_data = pad_sequences(question2_word_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "labels = np.array(is_duplicate, dtype=int)\n",
    "print('Shape of question1 data tensor:', q1_data.shape)\n",
    "print('Shape of question2 data tensor:', q2_data.shape)\n",
    "print('Shape of label tensor:', labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(open(Q1_TRAINING_DATA_FILE, 'wb'), q1_data)\n",
    "np.save(open(Q2_TRAINING_DATA_FILE, 'wb'), q2_data)\n",
    "np.save(open(LABEL_TRAINING_DATA_FILE, 'wb'), labels)\n",
    "np.save(open(WORD_EMBEDDING_MATRIX_FILE, 'wb'), word_embedding_matrix)\n",
    "with open(NB_WORDS_DATA_FILE, 'w') as f:\n",
    "    json.dump({'nb_words': nb_words}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Variables\n",
    "MODEL_WEIGHTS_FILE = 'question_pairs_weights_cnn_base.h5'\n",
    "MAX_SEQUENCE_LENGTH = 25\n",
    "EMBEDDING_DIM = 300\n",
    "VALIDATION_SPLIT = 0.1\n",
    "TEST_SPLIT = 0.1\n",
    "RNG_SEED = 13371447\n",
    "NB_EPOCHS = 25\n",
    "DROPOUT = 0.1\n",
    "BATCH_SIZE = 32\n",
    "nb_filter = 32 # Number of filters to use in Convolution1D\n",
    "filter_length = 3 # Length of filter for Convolution1D\n",
    "SENT_EMBEDDING_DIM = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1_train 363861\n",
      "Q2_train 363861\n",
      "Q1_test 40429\n",
      "Q2_test 40429\n"
     ]
    }
   ],
   "source": [
    "X = np.stack((q1_data, q2_data), axis=1)\n",
    "y = labels\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SPLIT, random_state=RNG_SEED)\n",
    "Q1_train = X_train[:,0]\n",
    "Q2_train = X_train[:,1]\n",
    "Q1_test = X_test[:,0]\n",
    "Q2_test = X_test[:,1]\n",
    "print(\"Q1_train\" , len(Q1_train))\n",
    "print(\"Q2_train\" , len(Q2_train))\n",
    "print(\"Q1_test\" , len(Q1_test))\n",
    "print(\"Q2_test\" , len(Q2_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "question1 = Input(shape=(MAX_SEQUENCE_LENGTH,))\n",
    "question2 = Input(shape=(MAX_SEQUENCE_LENGTH,))\n",
    "\n",
    "q1 = Embedding(nb_words + 1, \n",
    "                 EMBEDDING_DIM, \n",
    "                 weights=[word_embedding_matrix], \n",
    "                 input_length=MAX_SEQUENCE_LENGTH, \n",
    "                 trainable=False)(question1)\n",
    "\n",
    "q1 = Convolution1D(filters = nb_filter, \n",
    "                         kernel_size = filter_length, \n",
    "                         padding = 'same',  activation='relu')(q1)\n",
    "q1 = Flatten()(q1)\n",
    "#q3 = Lambda(lambda x: K.max(x, axis=1), output_shape=(EMBEDDING_DIM, ))(q3)\n",
    "\n",
    "q2 = Embedding(nb_words + 1, \n",
    "                 EMBEDDING_DIM, \n",
    "                 weights=[word_embedding_matrix], \n",
    "                 input_length=MAX_SEQUENCE_LENGTH, \n",
    "                 trainable=False)(question2)\n",
    "q2 = Convolution1D(filters = nb_filter, \n",
    "                         kernel_size = filter_length, \n",
    "                         padding = 'same', activation='relu')(q2)\n",
    "q2 = Flatten()(q2)\n",
    "\n",
    "merged = concatenate([q1,q2])\n",
    "is_duplicate = Dense(1, activation='sigmoid')(merged)\n",
    "\n",
    "model = Model(inputs=[question1,question2], outputs=is_duplicate)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 25)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 25)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 25, 300)      27437700    input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 25, 300)      27437700    input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 25, 32)       28832       embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 25, 32)       28832       embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 800)          0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 800)          0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 1600)         0           flatten_3[0][0]                  \n",
      "                                                                 flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1)            1601        concatenate_2[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 54,934,665\n",
      "Trainable params: 59,265\n",
      "Non-trainable params: 54,875,400\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training at 2018-05-06 22:30:27.113155\n",
      "Train on 327474 samples, validate on 36387 samples\n",
      "Epoch 1/25\n",
      " - 54s - loss: 0.5346 - acc: 0.7321 - val_loss: 0.5118 - val_acc: 0.7489\n",
      "Epoch 2/25\n",
      " - 54s - loss: 0.4926 - acc: 0.7605 - val_loss: 0.5042 - val_acc: 0.7578\n",
      "Epoch 3/25\n",
      " - 54s - loss: 0.4681 - acc: 0.7754 - val_loss: 0.5045 - val_acc: 0.7544\n",
      "Epoch 4/25\n",
      " - 54s - loss: 0.4499 - acc: 0.7852 - val_loss: 0.5066 - val_acc: 0.7563\n",
      "Epoch 5/25\n",
      " - 54s - loss: 0.4352 - acc: 0.7937 - val_loss: 0.5151 - val_acc: 0.7537\n",
      "Epoch 6/25\n",
      " - 54s - loss: 0.4225 - acc: 0.8003 - val_loss: 0.5143 - val_acc: 0.7581\n",
      "Epoch 7/25\n",
      " - 53s - loss: 0.4119 - acc: 0.8063 - val_loss: 0.5270 - val_acc: 0.7582\n",
      "Epoch 8/25\n",
      " - 54s - loss: 0.4028 - acc: 0.8112 - val_loss: 0.5334 - val_acc: 0.7558\n",
      "Epoch 9/25\n",
      " - 53s - loss: 0.3957 - acc: 0.8142 - val_loss: 0.5386 - val_acc: 0.7554\n",
      "Epoch 10/25\n",
      " - 54s - loss: 0.3886 - acc: 0.8180 - val_loss: 0.5485 - val_acc: 0.7507\n",
      "Epoch 11/25\n",
      " - 54s - loss: 0.3823 - acc: 0.8216 - val_loss: 0.5605 - val_acc: 0.7466\n",
      "Epoch 12/25\n",
      " - 54s - loss: 0.3772 - acc: 0.8246 - val_loss: 0.5641 - val_acc: 0.7532\n",
      "Epoch 13/25\n",
      " - 53s - loss: 0.3715 - acc: 0.8275 - val_loss: 0.5719 - val_acc: 0.7466\n",
      "Epoch 14/25\n",
      " - 54s - loss: 0.3666 - acc: 0.8299 - val_loss: 0.5812 - val_acc: 0.7513\n",
      "Epoch 15/25\n",
      " - 53s - loss: 0.3627 - acc: 0.8321 - val_loss: 0.5824 - val_acc: 0.7555\n",
      "Epoch 16/25\n",
      " - 53s - loss: 0.3584 - acc: 0.8343 - val_loss: 0.5967 - val_acc: 0.7476\n",
      "Epoch 17/25\n",
      " - 53s - loss: 0.3552 - acc: 0.8361 - val_loss: 0.5972 - val_acc: 0.7500\n",
      "Epoch 18/25\n",
      " - 53s - loss: 0.3517 - acc: 0.8377 - val_loss: 0.6020 - val_acc: 0.7549\n",
      "Epoch 19/25\n",
      " - 53s - loss: 0.3485 - acc: 0.8392 - val_loss: 0.6069 - val_acc: 0.7509\n",
      "Epoch 20/25\n",
      " - 53s - loss: 0.3452 - acc: 0.8406 - val_loss: 0.6188 - val_acc: 0.7504\n",
      "Epoch 21/25\n",
      " - 53s - loss: 0.3422 - acc: 0.8425 - val_loss: 0.6249 - val_acc: 0.7504\n",
      "Epoch 22/25\n",
      " - 53s - loss: 0.3394 - acc: 0.8437 - val_loss: 0.6280 - val_acc: 0.7480\n",
      "Epoch 23/25\n",
      " - 53s - loss: 0.3369 - acc: 0.8454 - val_loss: 0.6362 - val_acc: 0.7527\n",
      "Epoch 24/25\n",
      " - 53s - loss: 0.3342 - acc: 0.8462 - val_loss: 0.6462 - val_acc: 0.7520\n",
      "Epoch 25/25\n",
      " - 53s - loss: 0.3321 - acc: 0.8475 - val_loss: 0.6535 - val_acc: 0.7518\n",
      "Training ended at 2018-05-06 22:52:51.738999\n",
      "Minutes elapsed: 22.410427\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting training at\", datetime.datetime.now())\n",
    "t0 = time.time()\n",
    "callbacks = [ModelCheckpoint(MODEL_WEIGHTS_FILE, monitor='val_acc', save_best_only=True)]\n",
    "history = model.fit([Q1_train, Q2_train],\n",
    "                    y_train,\n",
    "                    epochs=NB_EPOCHS,\n",
    "                    validation_split=VALIDATION_SPLIT,\n",
    "                    verbose=2,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    callbacks=callbacks)\n",
    "t1 = time.time()\n",
    "print(\"Training ended at\", datetime.datetime.now())\n",
    "print(\"Minutes elapsed: %f\" % ((t1 - t0) / 60.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    epoch  training  validation\n",
      "0       1  0.732110    0.748894\n",
      "1       2  0.760482    0.757771\n",
      "2       3  0.775420    0.754390\n",
      "3       4  0.785220    0.756314\n",
      "4       5  0.793739    0.753676\n",
      "5       6  0.800348    0.758100\n",
      "6       7  0.806330    0.758155\n",
      "7       8  0.811249    0.755819\n",
      "8       9  0.814175    0.755380\n",
      "9      10  0.817992    0.750680\n",
      "10     11  0.821555    0.746585\n",
      "11     12  0.824569    0.753236\n",
      "12     13  0.827501    0.746640\n",
      "13     14  0.829944    0.751340\n",
      "14     15  0.832112    0.755490\n",
      "15     16  0.834286    0.747630\n",
      "16     17  0.836140    0.750048\n",
      "17     18  0.837734    0.754885\n",
      "18     19  0.839154    0.750900\n",
      "19     20  0.840629    0.750433\n",
      "20     21  0.842528    0.750378\n",
      "21     22  0.843667    0.747959\n",
      "22     23  0.845386    0.752714\n",
      "23     24  0.846220    0.752027\n",
      "24     25  0.847545    0.751752\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "acc = pd.DataFrame({'epoch': [ i + 1 for i in history.epoch ],\n",
    "                    'training': history.history['acc'],\n",
    "                    'validation': history.history['val_acc']})\n",
    "print(acc)\n",
    "ax = acc.iloc[:,:].plot(x='epoch',  grid=True)\n",
    "ax.set_ylabel(\"accuracy\")\n",
    "ax.set_ylim([0.0,1.0]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum accuracy at epoch 7 = 0.7582\n"
     ]
    }
   ],
   "source": [
    "max_val_acc, idx = max((val, idx) for (idx, val) in enumerate(history.history['val_acc']))\n",
    "print('Maximum accuracy at epoch', '{:d}'.format(idx+1), '=', '{:.4f}'.format(max_val_acc))\n",
    "model.load_weights(MODEL_WEIGHTS_FILE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.5298, accuracy = 0.7590\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate([Q1_test, Q2_test], y_test, verbose=0)\n",
    "print('loss = {0:.4f}, accuracy = {1:.4f}'.format(loss, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
